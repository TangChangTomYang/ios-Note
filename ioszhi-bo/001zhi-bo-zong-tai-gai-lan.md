

###直播总体概览
![](/assets/zhibo.png)

**音视频采集**
- 音视频的采集是直播架构的第一个环节，也是直播的视频来源。
- 采集的来源包括：
    - pc 端：屏幕摄像头（摄像头驱动适配）
    - ios端：摄像头采集（屏幕采集？）
    - android端：屏幕摄像头采集（硬件过多，适配一堆坑）

**前处理**
- 使用美颜相机&美图秀秀已经是网络发照片&发视频必备技能了
    - 80%主播没有美颜简直不能看
    - 不能看如何吸引用户&观众
    - 对视频进行美颜，已成标配
- 处理主要包括美颜、模糊处理、水印等
- 各平台处理方式：
    - pc端：美颜镜头、一些美颜软件
    - ios端：图像处理库是GPUImage,提供了丰富的预处理效果，也可利用该库自定义设计。
    - android端： Google开源的grafika,是一个非常强大的图形处理库。

**编码**
- 不经编码的视频非常的大，储存起来麻烦，更何况网络传输。
    - 编码通过压缩音频数据来减少数据体积，方便音视频数据的推流、拉流和存储，能大大提高存储传输效率。
    - 音视频必须经过压缩编码才能进行存储和传输。
    
- 编码方式：
    - 硬编码：使用非CPU进行编码，如：显卡GPU、专用DSP芯片等。
    - 软编码：使用CPU进行编码（手机容易发热）；

- 各个平台处理：
    - iOS端：硬件兼容性较好，可以直接进行硬编码。
    - androidd端： 硬件编码较难，难找到统一的库兼容各个平台（推荐使用软编码）。

- 编码标准：
    - 视频编码：H264、H265、VP8、VP9等
    - 音频编码：AAC、Opus
    
**传输**
- 从推流到服务端
    - 数据经过推流和预处理，编码之后推流到服务器端。
    - 流传输就设计到相应的传输协议，最常用的协议是 RTMP、RTSP、HLS 

- 搭建nginx + rtmp 服务进行推流演示。

**流分发**

- 音频流推到服务器后，为了适配个个平台端各种不同的协议，需要在服务端做一些流处理工作，比如转码成不同格式支持不同的协议，如：RTMP、HLS和FLV，以适应各个平台。
    - 比如：ios、android、pc、网页
- 甚至，为了适配一些运营需求，比如监管部门的要求，我们在服务端也提供了内容识别如：鉴黄的功能。

**播放**
- 拉流获取音频数据后，需要通过解码器解码，渲染才能在播放器上播放。
- 总体步骤：
    - 解协议：取出网络传输过程中一些无用信息。
    - 解封装：获取到的是音频&视频放在一起的封装文件。
    - 音视频解码：音视频都是通过压缩编码的内容，解码后才能进行播放。
    - 音视频同步： 视频&音频文件需要通过播放
    - 音视频播放： 声卡&显卡等对音视频进行播放
    
    
    
  
**主要直播技术：**
直播技术涉及的知识面很广，最主要的大概就是这几个：**软硬解码.h264、美颜处理、推流RTMP、拉流播放、视频录制、发送弹幕、即时通讯.**


**说明：**
- **软硬解码.h264**：使用iOS8.0之后苹果开源的VideoToolBox，这正是很多直播软件最低兼容iOS8的原因了

- **美颜处理**：CPUImage，内置150多种滤镜，功能强大
- **拉流播放**：ijkplayer.framework、VLC

- **推流RTMP**：安装nginx+rtmp服务器，ffmpeg推流
- **视频录制**：UIImagePiackerController、AVCaptureSession、GPUImageVideoCamera
- **发送弹幕**：BarrageRenderer第三方库
- **即时通讯**：XMPP、环信、融云等
    





